<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos7安装Redis]]></title>
    <url>%2F2018%2F04%2F08%2FCentos7%E5%AE%89%E8%A3%85Redis%2F</url>
    <content type="text"><![CDATA[安装环境：CentOS7 64位、Redis-4.0.8 下载安装包 切换到安装目录cd /usr/local/ 添加安装目录mkdir redis 切换安装目录cd redis 下载安装包wget http://download.redis.io/releases/redis-4.0.8.tar.gz 解压tar xzf redis-4.0.8.tar.gz 安装gcc如果不安装gcc 编译redis会报错yum install gcc 编译安装cd redis/redis-4.0.8/make MALLOC=libcRedis并没有自己实现内存池，没有在标准的系统内存分配器上再加上自己的东西。所以需要配置内存分配。不执行以上命令编译会报下面的错编译rediscd src &amp;&amp; make install 启动redis./redis-server如上图：redis启动成功，但是这种启动方式需要一直打开窗口，不能进行其他操作，不太方便。 以后台进程方式启动redis 修改redis.conf文件vim /usr/local/redis/redis-4.0.8/redis.conf将daemonize no 改为daemonize yes 指定redis.conf启动./redis-server /usr/local/redis/redis-4.0.8/redis.conf设置redis 开机启动 在/etc目录下新建redis目录mkdir redis 复制redis 配置文件cp /usr/local/redis/redis-4.0.8/redis.conf /etc/redis/6379.conf 复制redis 脚本到启动脚本目录中cp /usr/local/redis/redis-4.0.8/utils/redis_init_script /etc/init.d/redisd 切换到自启目录cd /etc/init.dchkconfig redisd on会显示service redisd does not support chkconfig看结果是redisd不支持chkconfig 解决方法：使用vim编辑redisd文件，在第一行加入如下两行注释，保存退出# chkconfig: 2345 90 10# description: Redis is a persistent key-value database注释的意思是，redis服务必须在运行级2，3，4，5下被启动或关闭，启动的优先级是90，关闭的优先级是10。再次执行开机自启命令，成功chkconfig redisd on 服务启动现在可以直接已服务的形式启动和关闭redis了启动：service redisd start关闭：service redisd stop 过程中的问题service redisd stop出现以下问题 Stopping …(error) NOAUTH Authentication required. 解决方法：因为我在配置redis 时候 配置了密码连接 所以 出现上面的问题,如果不配置 则不需要以下配置。修改启动脚本vim /etc/init.d/redisd增加密码设置变量,密码是你设置的redis密码 service启动或者关闭时出现以下问题 /var/run/redis_6379.pid exists, process is already running or crashed 解决方法：出现这个问题是因为redis 关闭不正常，导致文件没有被删除掉。执行以下命令即可删除rm -rf /var/run/redis_6379.pid]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装JDK1.8]]></title>
    <url>%2F2018%2F04%2F08%2FCentos7%E5%AE%89%E8%A3%85JDK1.8%2F</url>
    <content type="text"><![CDATA[安装环境：CentOS7 64位、JDK1.8 下载安装包 切换到安装目录cd /usr/local/ 添加安装目录mkdir java 切换安装目录cd java 下载安装包wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-x64.tar.gz&quot; 解压tar xzf jdk-8u161-linux-x64.tar.gz 配置环境变量 修改配置文件vim /etc/profile 添加以下配置JAVA_HOME=/usr/local/java/jdk1.8.0_161JRE_HOME=/usr/local/java/jdk1.8.0_161/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 更新文件source /etc/profile 验证java -verionjavac -version]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>JDK1.8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装MySQL5.7]]></title>
    <url>%2F2018%2F03%2F27%2FCentos7%E5%AE%89%E8%A3%85MySQL5.7%2F</url>
    <content type="text"><![CDATA[安装环境：CentOS7 64位、MySQL5.7 配置安装环境配置yum源rpm安装包wget http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 安装MySQL源yum localinstall mysql57-community-release-el7-8.noarch.rpm 检查mysql源是否安装成功yum repolist enabled | grep &quot;mysql.*-community.*&quot;看到上图表示安装成功 修改MySQL版本若默认安装5.7的话就不需要修改,修改源文件vim /etc/yum.repos.d/mysql-community.repo改变enabled属性改为1即可 安装MySQL yum install mysql-community-server一轮等待后 安装成功 启动MySQL systemctl start mysqld 查看MySQL状态 systemctl status mysqld 开机启动 systemctl enable mysqld systemctl daemon-reload 修改root本地登陆密码mysql安装完成之后，在/var/log/mysqld.log文件中给root生成了一个默认密码查看文件 grep &#39;temporary password&#39; /var/log/mysqld.log 登陆MySQL 修改密码 mysql -uroot -p ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;test!Wwh&#39;; 注意：mysql5.7默认安装了密码安全检查插件（validate_password），默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位。否则会提示ERROR 1819 (HY000): Your password does not satisfy the current policy requirements。 通过msyql环境变量可以查看密码策略的相关信息： show variables like &#39;%password%&#39;; validate_password_policy：密码策略，默认为MEDIUM策略 validate_password_dictionary_file：密码策略文件，策略为STRONG才需要 validate_password_length：密码最少长度 validate_password_mixed_case_count：大小写字符长度，至少1个 validate_password_number_count ：数字至少1个 validate_password_special_char_count：特殊字符至少1个 上述参数是默认策略MEDIUM的密码检查规则。 共有以下几种密码策略： 策略 检查规则 0 or LOW Length 1 or MEDIUM Length; numeric, lowercase/uppercase, and special characters 2 or STRONG Length; numeric, lowercase/uppercase, and special characters; dictionary file MySQL官网密码策略详细说明：http://dev.mysql.com/doc/refman/5.7/en/validate-password-options-variables.html#sysvar_validate_password_policy 修改密码策略在/etc/my.cnf文件添加validate_password_policy配置，指定密码策略validate_password_policy=0如果不需要 在my.cnf文件中添加如下配置禁用即可：validate_password = off重新启动MySQL 配置才会生效systemctl restart mysqld 添加远程登录用户默认只允许root帐户在本地登录，如果要在其它机器上连接mysql，必须修改root允许远程连接，或者添加一个允许远程连接的帐户，为了安全起见，我添加一个新的帐户：mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;wenthywang&#39;@&#39;%&#39; IDENTIFIED BY &#39;wwhtest123456&#39; WITH GRANT OPTION; 添加用户成功后 就可以远程使用mycat等工具连接了。 配置默认编码utf8 vim /etc/my.cnf 添加以下配置 character_set_server=utf8 //指定数据库编码为UTF-8 port=33060 //指定端口号 重新启动mysql服务，查看数据库默认编码如下所示： END]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的hexo部署到腾讯云服务器]]></title>
    <url>%2F2018%2F03%2F07%2Fhexo_deploy%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;最近发现腾讯云搞活动，然后就心血来潮买了个服务器，感觉是挺便宜的（肯定是腾讯的套路），还续费了2年，希望自己能玩好这台服务器。昨天刚买完之后，一直在想不知道用来干嘛，想到现在还是不清楚要搞些撒东西出来，所以索性就先把博客迁移到这台服务器吧。 服务器配置安装Gityum -y updateyum install -y git nginx安装git是因为hexo部署静态资源的时候需要有个git仓库安装nginx用来部署hexo静态资源文件 git安装后需要配置公钥，打开以下文件,把需要部署的客户端的公钥复制到这个文件中就行，这个操作在部署hexo的时候可以跳过openssh的密码验证。（可以不操作，操作更好） 在服务器上操作vim ~/.ssh/authorized_keys 在hexo客户端中操作 打开GIT GUI 找到HELP找到SHOW SSH KEY1ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAyPyy6mKAQrVQXVWCJ/2SeIDxF6a5FA8exlTTBtuAJZawpgRrnTCma+JFIvdViPH0fNIDLU0IwXZMExK5Gw2u90g3z0O2kJqF1pyAduyKUqd2oSK/aBGgcKCMej5OnS6xfDYqZn+zawsfU58ohUJHWNsXvTtK8XMGKi/N7nBsPxBqgwrTBMwHKIzhWjhv6SquQnnGaNXbddaidImixNyIHsbpJiPAQZtT4RH3WfCasBOtYF5Xl1ZMs07MiGEe+grX3MjrenMe1MJyWEziZTKREaV8jOgVbJi0EjpGTYqDb/oC6paqL4MbpQxQiFD70n2gOjSAyyVWEPfIHKaVl4z+cQ== Administrator@LQN-PC 复制key到authorized_keys 保存即可。PS:如果服务端重装系统了 则需要清除本地公钥缓存 使用以下命令ssh-keygen -R 111.230.24.31 新建git仓库cd /usr/local/wwhmkdir GitLibrarychmod -R 755 /data/GitLibrary 初始化git init --bare hexo.gitvim /usr/local/wwh/GitLibrary/hexo.git/hooks/post-receive 添加以下代码 12#!/bin/bashgit --work-tree=/usr/local/wwh/hexo --git-dir=/usr/local/wwh/GitLibrary/hexo.git checkout -f 保存并退出 给文件添加可执行权限chmod +x /usr/local/wwh/GitLibrary/hexo.git/hooks/post-receive 至此 git仓库配置完成。 nginx配置 nginx安装目录在/etc/nginx,配置测试性配置来检查是否安装成功了。 在/usr/local/wwh下新建文件夹 mkdir hexo cd hexo 新建index.html 文件 vim index.html文件内容如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Nginx running&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 3.配置 Nginx 服务器vim /etc/nginx/nginx.conf 添加以下配置 123456server &#123; listen 80 default_server; listen [::]:80 default_server; server_name localhost root /usr/local/wwh/hexo;//地址为刚才新建hexo文件夹 &#125; 4.启动Nginx 测试是否启动成功输入命令： systemctl start nginx.service在没有配置系统启动Nginx的时候只能使用这种方式 5.访问IP在浏览器输入IP地址：http://111.230.24.31/会显示Nginx running表明Nginx启动成功。 部署Hexo hexo 客户端安装 配置等不说明,在另外一篇文章中已经提及过了 1.修改nginx.conf 配置文件 vim /etc/nginx/nginx.conf 添加以下代码12345678910111213141516171819202122232425262728293031 server &#123; listen 80 default_server; listen [::]:80 default_server; server_name localhost; root /usr/local/wwh/hexo; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|flv|ico)$ &#123; expires 30d; access_log off; &#125; location ~ .*\.(eot|ttf|otf|woff|svg)$ &#123; expires 30d; access_log off; &#125; location ~ .*\.(js|css)?$ &#123; expires 7d; access_log off; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 代码中location 可不添加，location的配置主要是用来做页面缓存,提高访问性能,避免页面加载太慢。 重新启动nginxsystemctl restart nginx.service nginx 配置完成 2.hexo客户端配置 修改hexo中_config.yml 修改deploy 参数,修改为以下代码 123456deploy: type: git repo: github: git@github.com:wenthywang/wenthywang.github.io.git //部署到github wwh: root@111.230.24.31:/usr/local/wwh/GitLibrary/hexo //部署到腾讯云服务器 branch: master 执行hexo部署命令 hexo clean //清除本地资源hexo g -d //生成静态文件 并部署到配置文件中git地址 至此,hexo博客部署完毕。 为Nginx添加系统启动配置 在/etc/init.d/目录下编写脚本，名为nginx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112 #!/bin/sh # # nginx - this script starts and stops the nginx daemon # # chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \ # proxy and IMAP/POP3 proxy server # processname: nginx # config: /etc/nginx/nginx.conf # config: /etc/sysconfig/nginx # pidfile: /var/run/nginx.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0 nginx=&quot;/usr/local/nginx/sbin/nginx&quot; prog=$(basename $nginx) NGINX_CONF_FILE=&quot;/usr/local/nginx/conf/nginx.conf&quot; [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval &#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval killall -9 nginx &#125; restart() &#123; configtest || return $? stop sleep 1 start &#125; reload() &#123; configtest || return $? echo -n $&quot;Reloading $prog: &quot; killproc $nginx -HUP RETVAL=$? echo &#125; force_reload() &#123; restart &#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE &#125; rh_status() &#123; status $prog &#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1 &#125; case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;&quot; exit 2 esac 开启nginx服务chmod 755 /etc/init.d/nginxchkconfig --add nginx nginx启动，停止service nginx start//启动nginxservice nginx stop//停止nginxservice nginx restart//重启nginxservice nginx reload//修改配置后立马生效 通过系统配置后,nginx可以使用service nginx *的方式来启动了。 定时清除nginx日志1.修改nginx日志地址vim /etc/nginx/nginx.conf 修改以下内容error_log /etc/nginx/logs/error.log warn;access_log /etc/nginx/logs/access.log main; 2.重新启动nginx因为重新加载配置不生效，需要重新启动nginx。service nginx restart 3.添加定时任务（5天前的日志删除）cd /etc/nginxmkdir shcd shvim delete_nginx_logs.sh 添加以下代码 #set the path to nginx log files log_files_path=&quot;/etc/nginx/logs/&quot; save_days=5 #delete ? days ago nginx log files find $log_files_path -mtime +$save_days -exec rm -rf {} \; 修改定时任务crontab -e添加以下代码 保存00 00 * * * /bin/sh /etc/nginx/sh/delete_nginx_logs.sh每天0点0分执行脚本]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[预览office]]></title>
    <url>%2F2017%2F10%2F27%2Fview_office%2F</url>
    <content type="text"><![CDATA[各处搜寻最佳方案 项目中需要在线预览office文档的功能，因此在网络上搜寻大量资料。最终得到以下结论 使用开源openoffice 需要搭建openoffice服务 解析office文档转成pdf 然后通过控制器响应pdf的格式输出文档 再显示到页面 缺点是 ：效果不好 不推荐使用（简单的office文档或许还行） 使用第三方在线预览API 这个需要付费 推荐qq邮箱使用的永中第三方官网地址：http://dcs.yozosoft.com/注册账号可使用免费试用次数 效果还是很满意的 并且似乎支持所有格式的文档 txt… 使用微软提供url来解析office文档预览地址：https://products.office.com/zh-CN/office-online/view-office-documents-online这种方式是最省钱 省时间 缺点是有大小限制 以及文档类型（只支持office文档word，excel，ppt）官网有写 还有 解析效果不能自定义 但是效果还是蛮不错的 总的来说，如果不缺钱就选用第二种，可联系第三方是否可自定义什么的，如果没钱，可选用第三种（前提是部署应用的服务器可外网访问），第一种是备选状态。以上仅个人理解。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>在线预览</tag>
        <tag>office</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度文字识别API接入]]></title>
    <url>%2F2017%2F07%2F04%2FBaidu_API%2F</url>
    <content type="text"><![CDATA[First 一个偶然的链接进去了百度的管理控制台，一扫而过的各种功能真是厉害了。然后看到文字识别，之前帮别人开发一个模拟登陆获取数据（有点像爬虫），有个很关键的点就是验证码了。想了想百度可以文字识别，验证码就不过也如此。 注册百度账号 在文字识别添加一个应用 复制APPid和APPsecret 填写获取token的地址 发送请求123456String url = &quot;https://aip.baidubce.com/oauth/2.0/token&quot;; JSONObject obj=new JSONObject(); obj.put(&quot;grant_type&quot;, &quot;client_credentials&quot;); obj.put(&quot;client_id&quot;, &quot;XXX&quot;); obj.put(&quot;client_secret&quot;, &quot;YYY&quot;); String content=HttpUtil.post(url, &quot;json&quot;, obj.toJSONString(), null); 请求回来的数据是json字符串，解析一下就能获取token了。 Second 获取了token之后就要真正让百度帮我识别验证码了。这时候需要用到百度的sdk，这个包也是在百度的文档中提供，下载之后导入工程即可。 按照文档说，图片需要进行base64编码，还好sdk提供了工具类。 String url=&quot;https://aip.baidubce.com/rest/2.0/ocr/v1/webimage?access_token=&quot;+access_token; AipRequest r=new AipRequest(); String base64Img= Base64Util.encode( FileCopyUtils.copyToByteArray(file)); r.setUri(url); r.addHeader(&quot;Content-Type&quot;, &quot;application/x-www-form-urlencoded&quot;); HashMap&lt;String,Object&gt;params=new HashMap&lt;String,Object&gt;(); params.put(&quot;image&quot;, base64Img); r.setBody(params); AipResponse resp= AipHttpClient.post(r); System.out.println(resp.getBodyStr()); 响应后的数据就是有识别的结果了，返回来的数据也是json串，需要进行解析。 Finally 看了下token的过期时间，是一个月，所以我就把token转成json文件保存在本机，就不需要每次都要请求获取token了，另外在获取token的时候需要判断是否已经过期了。刚尝试了接触过的两种验证码，较为复杂的，有干扰线的，需要去除掉，然后进行图像处理，再调用百度的API才能识别出来，另外一种是没有干扰线的，这个直接调用就出现结果，准确率估计能达到90%，这个还是很不错的，个人觉得如果有这种需求的话可以使用百度的API，虽然有些次数限制，并发限制，总体来说还是可以的，不过也可以付费放开所有限制。]]></content>
      <categories>
        <category>验证码识别</category>
      </categories>
      <tags>
        <tag>百度API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring aop 初体验]]></title>
    <url>%2F2017%2F06%2F28%2FspringAOP%2F</url>
    <content type="text"><![CDATA[AOPAOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 AOP核心概念1、横切关注点 对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点 2、切面（aspect） 类是对物体特征的抽象，切面就是对横切关注点的抽象 3、连接点（joinpoint） 被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器 4、切入点（pointcut） 对连接点进行拦截的定义 5、通知（advice） 所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类 6、目标对象 代理的目标对象 7、织入（weave） 将切面应用到目标对象并导致代理对象创建的过程 8、引入（introduction） 在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段 Spring对AOP的支持Spring中AOP代理由Spring的IOC容器负责生成、管理，其依赖关系也由IOC容器负责管理。因此，AOP代理可以直接使用容器中的其它bean实例作为目标，这种关系可由IOC容器的依赖注入提供。Spring创建代理的规则为： 1、默认使用Java动态代理来创建AOP代理，这样就可以为任何接口实例创建代理了 2、当需要代理的类不是代理接口的时候，Spring会切换为使用CGLIB代理，也可强制使用CGLIB AOP的实现也不是难事，配置下文件（可用注解），可分3步。 1、定义普通业务组件 2、定义切入点，一个切入点可能横切多个业务组件 3、定义增强处理，增强处理就是在AOP框架为普通业务组件织入的处理动作 所以进行AOP编程的关键就是定义切入点和定义增强处理，一旦定义了合适的切入点和增强处理，AOP框架将自动生成AOP代理，即：代理对象的方法=增强处理+被代理对象的方法。 eg:aop.xml1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd&quot;&gt; &lt;/beans&gt; 基于Spring的AOP简单实现需要额外下载以下两个jar 1、aopalliance.jar 2、aspectjweaver.jar xml实现方式，注解方式就不多说了。 声明接口 12345public interface HelloWorld&#123; void printHelloWorld(); void doPrint();&#125; 添加接口实现 12345678910111213public class HelloWorldImpl implements HelloWorld&#123; public void printHelloWorld() &#123; System.out.println(&quot;Enter HelloWorldImpl.printHelloWorld()&quot;); &#125; public void doPrint() &#123; System.out.println(&quot;Enter HelloWorldImpl.doPrint()&quot;); return ; &#125;&#125; 横切关注点，这里是打印时间： 1234567public class TimeHandler&#123; public void printTime() &#123; System.out.println(&quot;CurrentTime = &quot; + System.currentTimeMillis()); &#125;&#125; -aop.xml配置12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd&quot;&gt; &lt;bean id=&quot;helloWorldImpl&quot; class=&quot;com.xrq.aop.HelloWorldImpl&quot; /&gt; &lt;bean id=&quot;timeHandler&quot; class=&quot;com.xrq.aop.TimeHandler&quot; /&gt; &lt;aop:config&gt; &lt;aop:aspect id=&quot;time&quot; ref=&quot;timeHandler&quot;&gt; &lt;aop:pointcut id=&quot;addAllMethod&quot; expression=&quot;execution(* com.xrq.aop.HelloWorld.*(..))&quot; /&gt; &lt;aop:before method=&quot;printTime&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt; &lt;aop:after method=&quot;printTime&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; main 方法 123456789101112public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;aop.xml&quot;); HelloWorld hw1 = (HelloWorld)ctx.getBean(&quot;helloWorldImpl&quot;); hw1.printHelloWorld(); System.out.println(); hw1.doPrint(); &#125; 结果 1234567CurrentTime = 1446129611993Enter HelloWorldImpl.printHelloWorld()CurrentTime = 1446129611993CurrentTime = 1446129611994Enter HelloWorldImpl.doPrint()CurrentTime = 1446129611994 总结 很不好意思地从度娘那拷过来的，暂时对aop的理解还没有这么深刻，但是使用过之后已经有了进一步的了解，然后再通过这篇博文发现对aop更加了解。以后对于一些能用aop方式解决的问题，还是用aop。 总得来讲，现在公司的所有模块都几乎没有用aop，这是有很大的优化空间啊，因为看到一堆重复的代码，真叫人费解。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下elasticsearch插件安装笔记(head,sql)]]></title>
    <url>%2F2017%2F05%2F04%2Felasticsearch_4%2F</url>
    <content type="text"><![CDATA[说明 这里的版本是es5.1.2，不适用5.x以下，5.x以下是用插件的形式安装在es上面，具体看git。 安装的目录，和解压的目录都可以随便选的，但是为了统一管理，最好全部插件安装在es的根目录下（个人建议），因为我这里此前有人安装过相关的插件，分散在不同的目录，搞起来让我很懵逼。 elasticsearch-headgithub链接 elasticsearch-head head 插件在window安装跟linux安装操作步骤基本相似，这里就介绍linux下安装即可。1.首先需要git clone head 插件到本地，在linux上使用git命令也行，下载到本地再上传到linux服务器也行，哪方便行。2.安装npm：使用国外镜像会比较慢，所以使用淘宝镜像，很快的。1wget https://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.4.7-linux-x64.tar.gz 3.解压：1tar -zxvf node-v4.4.7-linux-x64.tar.gz 4.设置环境变量：这个步骤很重要,直接影响到npm安装是否正确1export PATH=$PATH:/opt/node-v4.4.7-linux-x64/bin 这个opt是刚才解压的目录，这个一定不要错。5.查看npm版本： 1npm -v 看下有没有版本号，有的话就没问题了。没有的话应该是环境变量出问题了，先看下当前环境变量 1echo $PATH 有上一步的安装目录的话，就没有问题了，这时候需要你重新设置环境变量 1export PATH=把刚才path的值拷贝过来就可以了 然后重新npm -v 看下，如果还是不行，建议重新安装npm。 另外还有一个很奇葩的东西，不知道是不是linux自带了node，会导致环境变量有问题，如果发现自带的node，请务必要删掉，然后重新设置PATH。 另外装完npm之后可以装n插件，这个插件可以更新最新版本的node，具体详情可以bing一下。 6.在head插件根目录下安装npm和grunt插件 12npm install cnpm --registry=https://registry.npm.taobao.orgnpm install grunt–cli 7.修改Elasticsearch配置文件 编辑elasticsearch-5.1.1/config/elasticsearch.yml,加入以下内容： 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 8.修改Gruntfile.js打开elasticsearch-head-master/Gruntfile.js，找到下面connect属性，新增hostname: ‘0.0.0.0’,同时里面的port参数是对应的端口号，访问的时候就是这个端口号了，按需配置。 12345678910connect: &#123; server: &#123; options: &#123; hostname: &apos;0.0.0.0&apos;, port: 9100, base: &apos;.&apos;, keepalive: true &#125; &#125; &#125; 9.启动elasticsearch-head在elasticsearch-head-master/目录下，运行启动命令: 1grunt server 这个操作可能会出现异常，提示插件找不到，所以要找到elasticsearch-head-master/目录下的package.json里面最后的”devDependencies”参数，安装需要的插件包。 1npm install 插件名@版本号 安装完再启动就好了。 10.后台启动elasticsearch-head 1nohup grunt server &amp;exit 如果想关闭head插件，使用Linux查找进程命令： 1ps aux|grep head 结束进程： 1kill 进程号 至此，head插件已成功安装。 elasticsearch-sql github链接 elasticsearch-sql由于上面已经安装好整个环境了，就不需要再安装了，如果是反过来装的话，也要先装npm才行。 1.下载es-sql-site压缩包[https://github.com/NLPchina/elasticsearch-sql/releases/download/5.0.1/es-sql-site-standalone.zip]并解压到相应目录。2.切换到解压目录，并安装express插件，同时部署node服务。123cd site-servernpm install express --savenode node-server.js 至此sql插件已成功安装,同样如果需要后台运行，需要使用nohup命令执行。另外sql端口号的配置在es-sql-site\site-server目录下的site_configuration.json文件中配置。 总结 插件安装可能比较繁琐，特别是npm的安装，需要耐心。另外配置链接的地址可以写死在js里面 这个的链接配置在head-master目录下elasticsearch-head-master_site\app.js1line 4327 &quot;http://localhost:9200&quot; -&gt;&quot;http://172.16.54.74:19200&quot; 配置成启动的es的ip和端口即可 这个的链接配置在head-master目录下es-sql-site_site\controller.js line 387 url = &quot;http://localhost:9200&quot;-&gt;&quot;http://172.16.54.74:19200&quot; line 390 url = location.protocol+&apos;//&apos; + location.hostname + (location.port ? &apos;:&apos;+location.port : &apos;&apos;)-&gt;&quot;http://172.16.54.74:19200&quot; 都改成启动的es的ip和端口即可，这样子就不需要每次打开插件都填写对应的ip和port了。]]></content>
      <categories>
        <category>elasticsearch</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>elasticsearch插件</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch-sql-5.1.2笔记]]></title>
    <url>%2F2017%2F03%2F27%2Felasticsearch_3%2F</url>
    <content type="text"><![CDATA[elasticsearch-sql-5.1.2elasticsearch-sql ElasticSearch-sql 是es的插件之一，通过类sql查询es。最近更新了最新的5.1.2版本，出现某些异常情况。使用groupby的时候查询的时候只有10条，出现这个问题，尝试了在issue找答案，找到了发送请求的时候要设置size的大小，而sql插件源码包里面写死了200和10，至于怎么找出来的，我也是在别人的博客里面看到的，blog。因此，通过修改源码重新打包即可解决我的问题（源码包就跟打好的jar包放一起，名字也写上了source，多贴心），修改两个位置,如下line 76:这个位置是最后一次查询条数，改成Integer.MAX_VALUE。123if(select.getRowCount()&gt;0) &#123; ((TermsAggregationBuilder) lastAgg).size(Integer.MAX_VALUE); &#125; line 109:这个位置是重点，每次的子查询都要设置size，改成Integer.MAX_VALUE。12345AggregationBuilder subAgg = getGroupAgg(field, select); //ES5.0 termsaggregation with size = 0 not supported anymore if (subAgg instanceof TermsAggregationBuilder &amp;&amp; !(field instanceof MethodField)) &#123; ((TermsAggregationBuilder) subAgg).size(Integer.MAX_VALUE); &#125; 里面注释也有说到，5.0以上已经不支持size为0的设置，所以要设置值，不设置的话默认是10。这个问题在线上已经出现了，先准备升级修复这个问题。另外，如果数据超出了Integer.MAX_VALUE，则需要加上更多的过滤条件，似乎超过了查询就会出问题了，这个问题并没有深究。 总结 找这个问题的过程虽然艰辛，学习的过程让我很快乐，同时我也在es讨论网站也发出相关问题，跟相关的es使用者一起讨论，得到他们的回答，我也是想当开心的。Anyaway ，发现看源码真的让自己学习了很多。discuss.elastic.co]]></content>
      <categories>
        <category>elasticsearch</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>elasticsearch-sql</tag>
        <tag>group_by</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 笔记-插件]]></title>
    <url>%2F2016%2F12%2F30%2Felasticsearch_2%2F</url>
    <content type="text"><![CDATA[delete-by-query插件使用1TransportClient.builder().settings(settings).addPlugin(DeleteByQueryPlugin.class).build(); deleteByQuery插件是通过按照查询出来的doc 来进行删除操作。 es的集群都需要安装deleteByQuery 插件，到es的安装目录里执行plugin install deletebyQuery命令则可安装 es安装完需要重启，重新加载插件 客户端创建时需要添加plugin的支持如上面代码 eg： 1234567891011121314151617181920/** * es 查询删除操作 * @param index 索引 * @param type 类型 * @param column 删除字段的列名 * @param deleteValue 删除字段值 * @return long 删除结果 */ public long deleteByQuery (String index,String type,String column,String deleteValue) &#123; String deleteByQuery=&quot;&#123;\&quot;query\&quot;:&#123;\&quot;bool\&quot;:&#123;\&quot;must\&quot;:[&#123;\&quot;term\&quot;:&#123;\&quot;&quot;+column+&quot;\&quot;:\&quot;&quot;+deleteValue+&quot;\&quot;&#125;&#125;]&#125;&#125;&#125;&quot;; LOG.info(&quot;[EsJdbcDaoSupport.deleteByQuery] request json-&gt; &quot;+deleteByQuery); DeleteByQueryResponse response = new DeleteByQueryRequestBuilder(EsConnectionFactory.transportClient, DeleteByQueryAction.INSTANCE) .setIndices(index) .setTypes(type) .setSource(deleteByQuery) .execute() .actionGet(); return response.getTotalFound(); &#125; 这种方式是通过拼装请求json 来获得查询条件，然后es发送json查询。 12345678910111213141516171819/** * 查询es记录 * * @param index 数据库 * @param type 表 * @param dataMap 字段对应的数据 * @return boolean */public long delete (String index,String type,String deleteId) &#123; TransportClient client =EsConnectionFactory.createEsClient(); DeleteByQueryResponse response = new DeleteByQueryRequestBuilder(client, DeleteByQueryAction.INSTANCE) .setIndices(index) .setTypes(type) .setQuery(QueryBuilders.boolQuery().must(QueryBuilders.termQuery(&quot;QS_ENTERPRISE_ID&quot;, deleteId))) .execute() .actionGet(); return response.getTotalFound();&#125; 这种方式是通过原生es的查询查询数据，两种效果一样，不过我还是比较喜欢第二种。第一种可以动态生成查询条件，第二种动态生成好像是不行。 update-by-query 插件使用1TransportClient.builder().settings(settings).addPlugin(ReindexPlugin.class).build(); update-by-query插件是通过按照查询出来的doc 来进行更新操作，主要原理应该是：es不支持直接操作es单条记录，所以要把更新的记录拿出来，然后删除原来的，把更新后插入进去。 es 不需要安装，不需要重启 工程中添加reindex.jar，jar包在下载es里面的lib中可以找到 客户端创建时需要添加plugin的支持如上面代码 eg： 123456UpdateByQueryRequestBuilder ubqrb=UpdateByQueryAction.INSTANCE.newRequestBuilder(client);BulkIndexByScrollResponse r=ubqrb.source(INDEX_ST_SESSION_TAG_SDR) .script(new Script(&quot;[ctx._source.ST_TAG_ID2=0,ctx._source.ST_TAG_ID3=0]&quot;)) .filter(QueryBuilders.boolQuery().must(QueryBuilders.termQuery(&quot;ST_ENTERPRISE_ID&quot;, orgName))) .filter(QueryBuilders.boolQuery().must(QueryBuilders.termQuery(&quot;ST_TAG_ID2&quot;, tagid))) .get(); update-by-query 的难点在于一开始的script的写法，一开始不懂如何写script，后来看了各种文档api，才发现ctx.source是最重要的一个参数。后面的才是es的对应的列名（mapping），个人感觉ctx代表了所有数据的所有属性。 总结通过学习两种插件的使用，更加了解了es的运作，现在用的是2.4.1的版本。没有升级，好像5的版本已经自带插件了，不需要再手动添加插件了。不过，还是觉得es配合sql的操作还是不让人放心。复杂的业务操作还是用原生的es，不需要用sql插件，不然会出现一些不可预知的情况。]]></content>
      <categories>
        <category>elasticsearch</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>elasticsearch-插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csv 笔记]]></title>
    <url>%2F2016%2F12%2F02%2Fcommon-csv%2F</url>
    <content type="text"><![CDATA[csv初使用COMMON-CSV官网 项目中批量插入数据库使用的mybatis，在做数据导入的时候，觉得是mybatis的批量导入有问题，后来发现其实是没问题的。当时没看时间花费多少，就找到了common-csv来做测试，在知乎上也有很多人说用csv配合load data会很快，后来测试之后，其实感觉是差不多的，我的数据量是1000左右，可能在1w以上的数据就会出现差异，load data 这个东西感觉是效率很高，使用起来也是很方便，在项目中引用common-csv的jar包即可 示例 mybatis xml 文件配置 1234567891011&lt;insert id=&quot;createOrdersByCsv&quot; &gt; LOAD DATA LOCAL INFILE #&#123;filePath&#125; INTO TABLE wo_work_order_test FIELDS TERMINATED BY &apos;,&apos; lines terminated by &apos;\r\n&apos;(ID, ENTERPRISE_ID, ORDER_NO,CUSTOMER_ID,STATUS,PRIORITY,SUBJECT,CONTENT,SOURCE,WORKGROUP,AGENT,IS_DELETE,STRATEGY,HAS_FILES,DISPATCH_STATUS,BATCH_NO,CREATE_TIME,UPDATE_TIME,OVER_TIME,HANDING_OVER_TIME,OVER_TIME_FLAG,HANDING_OVER_TIME_FLAG,WG_RECEIVE_TIME,AG_RECEIVE_TIME); &lt;/insert&gt; java 代码生成csv文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/** * 通过Csv文件导入mySql数据库 * @param entities 实体list * @return boolean 导入结果 */ private boolean createOrdersByCsv(List&lt;OrderEntity&gt;entities)&#123; boolean result=false; String filename = &quot;/usr/local/jiaxin_gw_container-1.0/tmp/&quot;+TimeUtils.getCurrentTimeStamp()+&quot;orders-tmp.csv&quot;; try &#123; CSVFormat csvFileFormat = CSVFormat.RFC4180.withRecordSeparator(&quot;\n&quot;);// 创建CSVFormat OutputStreamWriter write = new OutputStreamWriter(new FileOutputStream(filename),&quot;UTF-8&quot;); BufferedWriter bufferedWriter = new BufferedWriter(write); CSVPrinter csvFilePrinter = new CSVPrinter(bufferedWriter, csvFileFormat); StringBuilder recordStr = new StringBuilder(); for (OrderEntity entity : entities) &#123; recordStr.append(entity.getID() + &quot;,&quot;); recordStr.append(entity.getEnterpriseID() + &quot;,&quot;); recordStr.append(entity.getOrderNo() + &quot;,&quot;); if(entity.getCustomerJID()==null)&#123; recordStr.append(&quot;\\N&quot; + &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getCustomerJID() + &quot;,&quot;); &#125; recordStr.append(entity.getStatus() + &quot;,&quot;); recordStr.append(entity.getPriority() + &quot;,&quot;); if(entity.getSubject()==null)&#123; recordStr.append(&quot;\\N&quot;+ &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getSubject() + &quot;,&quot;); &#125; if(entity.getDescription()==null)&#123; recordStr.append(&quot;\\N&quot; + &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getDescription() + &quot;,&quot;); &#125; recordStr.append(entity.getSource() + &quot;,&quot;); if(entity.getAcceptWkgroupJID()==null)&#123; recordStr.append( &quot;\\N&quot;+ &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getAcceptWkgroupJID()+ &quot;,&quot;); &#125; if(entity.getAcceptAgentJID()==null)&#123; recordStr.append(&quot;\\N&quot;+ &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getAcceptAgentJID() + &quot;,&quot;); &#125; recordStr.append(entity.getIsDelete() + &quot;,&quot;); recordStr.append(entity.getDispatchStrategy() + &quot;,&quot;); recordStr.append(entity.getHasAttach()+ &quot;,&quot;); recordStr.append(entity.getDispatchStatus()+ &quot;,&quot;); recordStr.append(entity.getBatchNo()+ &quot;,&quot;); recordStr.append(entity.getCreateTime()+ &quot;,&quot;); recordStr.append(entity.getUpdateTime()+ &quot;,&quot;); if(entity.getTimeoutTime()==null)&#123; recordStr.append(&quot;\\N&quot;+ &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getTimeoutTime()+ &quot;,&quot;); &#125; if(entity.getHandingOverTime()==null)&#123; recordStr.append(&quot;\\N&quot;+ &quot;,&quot;); &#125;else&#123; recordStr.append(entity.getHandingOverTime()+ &quot;,&quot;); &#125; recordStr.append(entity.getOverTimeFlag()+ &quot;,&quot;); recordStr.append(entity.getHandingOverTimeFlag()); recordStr.append(&quot;\r\n&quot;); &#125; recordStr.deleteCharAt(0); recordStr.deleteCharAt(recordStr.length()-1); csvFilePrinter.printRecord(recordStr.toString()); recordStr.delete(0, recordStr.length()-1); csvFilePrinter.close(); orderDao.createOrdersByCsv(filename); result=true; &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return result; &#125; 上面的\N是null的String插入到mysql为null，如果不使用\N，插入到数据库就是null的字符串，显然不对。 总结 在使用过程中，生成csv文件中，产生的头尾双引号，还没有找到解决方法，所以导致插入数据库是有双引号的。 需要在api文档中找寻相关解决方法。这是一个问题。 还有就是分隔符的问题，导入的数据要是比较正常的数据还好，如果出现跟分割符相同的数据，会直接导致插入的数据90%的错误，这个是很严重的问题，所以用的时候要注意。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>csv</tag>
        <tag>myslq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Future Callable 初使用]]></title>
    <url>%2F2016%2F11%2F19%2FFuture_Use%2F</url>
    <content type="text"><![CDATA[线程优化 昨天看到一同事的导出代码，单线程，看着就觉得还是差了点东西。然后就想进行一番改造，然后就找来了future和callable。 Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，Future可以拿到异步执行任务的返回值。 简单来说就是一个是执行任务，然后它带着任务执行的结果回来。 简单看下下面的demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import java.util.ArrayList;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class demo&#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ExecutorService executor = Executors.newCachedThreadPool(); ArrayList&lt;Future&lt;Integer&gt;&gt; resultList = new ArrayList&lt;&gt;(); //创建并提交任务1 AddNumberTask task1 = new AddNumberTask(1, 5000); Future&lt;Integer&gt; future1 = executor.submit(task1); resultList.add(future1); //创建并提交任务2 AddNumberTask task2 = new AddNumberTask(5001, 10000); Future&lt;Integer&gt; future2 = executor.submit(task2); resultList.add(future2); executor.shutdown(); int total = 0; for(Future&lt;Integer&gt; future : resultList)&#123; while(true)&#123; if(future.isDone() &amp;&amp; !future.isCancelled())&#123; int sum = future.get(); total += sum; break; &#125; else&#123; Thread.sleep(100); &#125; &#125; &#125; System.out.println(&quot;total sum is &quot; + total); &#125;&#125;class AddNumberTask implements Callable&lt;Integer&gt;&#123; private int start; private int end; public AddNumberTask(int start, int end) &#123; // TODO Auto-generated constructor stub this.start = start; this.end = end; &#125; @Override public Integer call() throws Exception &#123; // TODO Auto-generated method stub int totalSum = 0; for(int i = start; i &lt;= end; i++)&#123; totalSum += i; &#125; Thread.sleep(5000); return totalSum; &#125; &#125; 参考了这个例子，我就改造了导出的那段代码，1w2数据从原来的6-8s 到现在的2-3s，虽然不是很多，但是也是一大进步，后来想了下，时间其实就花在了查询的sql，如果sql 再继续优化下去的的话应该可以突破到1s执行返回的。但因为还有新需求要进行，我就不再细究下去了。 改造的时候，同样我也是根据查询的数据量来新建任务执行，使用了for循环，本来公司已经提供了线程池fixedPool(100)的，我就不用自己再创建了。 出现的问题 future 没有表示返回来的这堆数据是谁的于是我就对返回变量进行了修改，返回一个map，标识这个数据是我的，后面根据map的key获取数据。 size 数据量的大小影响任务的执行查询数据使用了limit 字段每次查询1000 2000 3000 500 这几个size 都试过，似乎值越大越好，一次查询数据量比多次查询数据量效率要高。因为3000恐怕生产环境的数据会比较多，后来我就改成了2000。 mysql 索引 不合理索引建不好，导致查询sql也是很慢的，查询的那个表使用了多列索引，问题就出在这了，使用sql的执行计划看了下，查询的字段虽然有索引但是没有使用到，因为多列索引的第一个不是我的查询字段，导致查询效率会有小小的降低，我也没跟负责人说，毕竟也不是很大的问题，差的时间不是很多。]]></content>
      <categories>
        <category>笔记</category>
        <category>Java</category>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>Future</tag>
        <tag>excel导出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[next部署git页面资源加载404]]></title>
    <url>%2F2016%2F11%2F18%2Fnext%2F</url>
    <content type="text"><![CDATA[资源404 引用一下其他博主的话，这位博主不要生气哦，资源共享嘛 最近github page更新了，GitHub Pages 过滤掉了 source/vendors 目录的访问，所以next主题下的source下的vendors目录不能够被访问到，所以就出现了本地hexo s能够正常访问，但是deploy到github就是一片空白，按f12，可以看到大量来自source/vendors的css和js提示404 这两天推送git的时候发现，推送hexo成功，但是在github上面打开就报了一堆404找不到资源的情况。所有的配置都已经配置好的，跟以前没有什么区别，然后自己再反复找下是不是hexo的问题，然后就重新装了hexo。发现问题还是存在，于是就度娘了一下，原来最近真的有这样情况，然后next的博主也在git上面解决了这个bug，详情请看资源加载失败，原来是有个jekyll的东西改了，导致不能加载这些资源。 看到比较快的解决方法，亲测成功，因为我把博主的master的git删掉了，我在想当初我怎么这么手贱啊。同时我也改了挺多博主的东西，免得冲突了。听说博主更新了很多东西，最近实在是太忙了，没有去研究博主的新东西。我还是很喜欢next 这个主题的。更好的方法应该是直接更新博主的next master了。 解决方法 参考: issue: #1220 步骤:123456.deploy_git 目录, 添加 .nojekyll 空文件source目录, 添加.nojekyll 空文件修改 Hexo 上层_config.yml配置文件, 添加include: - .nojekyll重新部署推送: hexo d -g 同时出现的问题 添加以上内容的时候，还发现win10直接添加.xx的文件是不行。后来想到绝招，使用git bash 添加文件，真是无所不能。git base的命令跟linux的命令几乎一样，所以一下就建好了。新建文件命令 1touch .nojekyll 这个bug 就解决到这了。嘻嘻]]></content>
      <categories>
        <category>笔记</category>
        <category>bug</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch 笔记]]></title>
    <url>%2F2016%2F11%2F18%2Felasticsearch_1%2F</url>
    <content type="text"><![CDATA[初学elasticsearchelasticsearch，简称ES。百度百科 ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。我们建立一个网站或应用程序，并要添加搜索功能，令我们受打击的是：搜索工作是很难的。我们希望我们的搜索解决方案要快，我们希望有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP的索引数据，我们希望我们的搜索服务器始终可用，我们希望能够一台开始并扩展到数百，我们要实时搜索，我们要简单的多租户，我们希望建立一&gt; 个云的解决方案。Elasticsearch旨在解决所有这些问题和更多的问题。 elasticsearch 安装 安装elasticsearch简单，容易。我使用的es是2.4.1版本的，elasticsearch下载。另外Java也是必须的，最好是1.7以上的版本，我用的是1.7的java版本的。 下载好之后，打开根目录下的bin目录下的elasticsearch.bat，如下：其实就是本地开了服务，跟web工程差不多。 打开之后，就可以本地玩耍了。es默认使用9200，9300端口的，详细配置可以参考官方文档，也可以自己参详参详。在浏览器上输入localhost：9200 可见配置信息，以及开启信息，如下图： elasticsearch插件安装 es有两个插件，一个是head的插件，可以看到es的集群状态。一个是sql插件，可以用类似sql的语句查询数据。具体的安装可以百度或者google查找哦。 强大的Elasticsearch-sql Elasticsearch-sql是一个强大的插件，界面上可以用sql查询，代码上可以用sql执行sql语句，相对于es的原生态，我还是比较喜欢这种sql开发的，因为一开始我是使用原生态的查询聚合查询，写得也DT的。后来加了sql插件，开发效率都提高了不少，但是使用起来也是有一定的限制。 group by 后面的字段不能为空 字段类型需要groupby的需要设置not_analyzed 保证这个字段不分析，当出现一些特殊字符的时候，不加的话es会默认使用分析，分词功能，就达不到要的效果，当时也是纠结了好久才发现的。 创建es链接麻烦，每次查询需要创建链接，没有连接池，虽然后面用了druid连接，似乎会出问题。 es put连接创建一次就好了，后来就使用了类加载，一次连接即可，减少多次连接造成的消耗。 总结使用还是很方便的，特别是用sql。不过对于业务复杂的似乎不怎么样，另外同时使用redis做缓存是最好不过了。 查询效率是很高，后期维护也是需要挺高的成本的。总体来说实时性还是挺强的，苦逼的我现在还在加班... 之前写了一半，今天就写完它吧，也是写得很急，有什么要交流的可以留言。或者加微信详聊哦。]]></content>
      <categories>
        <category>elasticsearch</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven mirror修改 国内镜像]]></title>
    <url>%2F2016%2F11%2F02%2Fmaven_mirror%2F</url>
    <content type="text"><![CDATA[修改setting.xml setting.xml是工程所用的maven的setting.xml,可存在maven安装目录的conf下，或者在.m2下面。修改 .m2 文件夹中的setting.xml 中的 元素。添加子元素如下：1234567&lt;mirrors&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 阿里云的镜像，亲测很快。以后都用它了。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git工程批量更新和自动提交]]></title>
    <url>%2F2016%2F09%2F22%2Fgit_push%2F</url>
    <content type="text"><![CDATA[git工程批量更新用gitbash客户端都有一种不爽，更新多个工程需要很多的fetch，rebase，stash等命令，所以无聊就看了下shell脚本，看能不能批量fetch，rebase，搞了下，还是可以的，不过我这个是直接pull，直接合并到当前工程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#/bin/bashecho '**********选择更新的git项目**********'echo '0.all'echo '1.jiaxin_lib_core'echo '2.jiaxin_lib_dubbox'echo '3.jiaxin_web_devcenter'echo '4.jiaxin_web_agent'echo '5.jiaxin_web_conf'echo '6.jiaxin_gw_statistics'echo '7.jiaxin_gw_config'echo '8.jiaxin_gw_container'echo '9.jiaxin_gw_order'read project #在控制台输入1 2 3，它们之间用空格隔开。if test $project -eq 0 ;thenecho '------------------------jiaxin_lib_core-----------------------'cd jiaxin_lib_core &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_lib_dubbox-----------------------'cd jiaxin_lib_dubbox &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_web_devcenter-----------------------'cd jiaxin_web_devcenter &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_web_agent-----------------------'cd jiaxin_web_agent &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_web_conf-----------------------'cd jiaxin_web_conf &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_gw_statistics-----------------------'cd jiaxin_gw_statistics &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_gw_config-----------------------'cd jiaxin_gw_config &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_gw_container-----------------------'cd jiaxin_gw_container &amp;&amp; git checkout *.jar &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_gw_order-----------------------'cd jiaxin_gw_order &amp;&amp; git pull &amp;&amp; cd ..fiif test $project -eq 1 ;then echo '-----------------------jiaxin_lib_core-START-----------------------' cd jiaxin_lib_core &amp;&amp; git pull &amp;&amp; cd ..echo '------------------------jiaxin_lib_core-END-----------------------';fiif test $project -eq 2 ;thenecho '------------------------jiaxin_lib_dubbox-START----------------------'cd jiaxin_lib_dubbox &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_lib_dubbox-END-----------------------';fiif test $project -eq 3 ;thenecho '------------------------jiaxin_web_devcenter-START----------------------'cd jiaxin_web_devcenter &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_web_devcenter-END-----------------------';fiif test $project -eq 4 ;thenecho '------------------------jiaxin_web_agent-START----------------------'cd jiaxin_web_agent &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_web_agent-END-----------------------';fiif test $project -eq 5 ;thenecho '------------------------jiaxin_web_conf-START----------------------'cd jiaxin_web_conf &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_web_conf-END-----------------------';fiif test $project -eq 6 ;thenecho '------------------------jiaxin_gw_statistics-START----------------------'cd jiaxin_gw_statistics &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_gw_statistics-END-----------------------';fiif test $project -eq 7 ;thenecho '------------------------jiaxin_gw_config-START----------------------'cd jiaxin_gw_config &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_gw_config-END-----------------------';fiif test $project -eq 8 ;thenecho '------------------------jiaxin_gw_container-START----------------------'cd jiaxin_gw_container &amp;&amp; git checkout *.jar &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_gw_container-END-----------------------';fiif test $project -eq 9 ;thenecho '------------------------jiaxin_gw_order-START----------------------'cd jiaxin_gw_order &amp;&amp; git pull &amp;&amp; cd ..echo '-----------------------jiaxin_gw_order-END-----------------------';fi git工程push#/bin/bash echo '**********选择push的git项目**********' echo '1.jiaxin_lib_core' echo '2.jiaxin_lib_dubbox' echo '3.jiaxin_web_devcenter' echo '4.jiaxin_web_agent' echo '5.jiaxin_web_conf' echo '6.jiaxin_gw_statistics' echo '7.jiaxin_gw_config' echo '8.jiaxin_gw_order' read project echo '请输入提交参数commit：' read commit #在控制台输入1 2 3，它们之间用空格隔开。 if test $project -eq 1 ;then echo '-----------------------jiaxin_lib_core-START-----------------------' cd jiaxin_lib_core &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '------------------------jiaxin_lib_core-END-----------------------'; fi if test $project -eq 2 ;then echo '------------------------jiaxin_lib_dubbox-START----------------------' cd jiaxin_lib_dubbox &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_lib_dubbox-END-----------------------'; fi if test $project -eq 3 ;then echo '------------------------jiaxin_web_devcenter-START----------------------' cd jiaxin_web_devcenter &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_web_devcenter-END-----------------------'; fi if test $project -eq 4 ;then echo '------------------------jiaxin_web_agent-START----------------------' cd jiaxin_web_agent &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_web_agent-END-----------------------'; fi if test $project -eq 5 ;then echo '------------------------jiaxin_web_conf-START----------------------' cd jiaxin_web_conf &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_web_conf-END-----------------------'; fi if test $project -eq 6 ;then echo '------------------------jiaxin_gw_statistics-START----------------------' cd jiaxin_gw_statistics &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_gw_statistics-END-----------------------'; fi if test $project -eq 7 ;then echo '------------------------jiaxin_gw_config-START----------------------' cd jiaxin_gw_config &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_gw_config-END-----------------------'; fi if test $project -eq 8 ;then echo '------------------------jiaxin_gw_order-START----------------------' cd jiaxin_gw_order &amp;&amp; git add -A &amp;&amp; git commit -m $commit &amp;&amp; git push origin HEAD:refs/for/master &amp;&amp; cd .. echo '-----------------------jiaxin_gw_order-END-----------------------'; fi 执行脚本使用git客户端切换到git的根目录，执行脚本命令即可。 ./update.sh 或 ./push.sh 注意事项 脚本放到git根目录，其实不放也可以的。你喜欢，我的脚本位置 根据个人需要修改相应git命令，以免造成代码混乱，容易产生冲突 还有push的时候，也是需要按照个人需要修改的，因为git add的时候是全部的，最好区分一下 相关代码已上传到github 链接]]></content>
      <categories>
        <category>GIT</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis调用存储过程报错]]></title>
    <url>%2F2016%2F09%2F20%2FMybatis_error%2F</url>
    <content type="text"><![CDATA[Mybatis调用存储过程贴码123456Error querying database. Cause: java.sql.SQLException: User does not have access to metadata required to determine stored procedure parameter types. If rights can not be granted, configure connection with "noAccessToProcedureBodies=true" to have driver generate parameters that represent INOUT strings irregardless of actual parameter types. The error may exist in resources/mapper/AgentStatisDao.xml The error may involve com.jiaxincloud.gw.statistics.dao.statistics.AgentStatisDao.callAgentVisitorManualStatisProcedure The error occurred while executing a query SQL: &#123;CALL PRO_AGENT_VISITOR_MANUAL_STATIS(?,?,?)&#125; Cause: java.sql.SQLException: User does not have access to metadata required to determine stored procedure parameter types. If rights can not be granted, configure connection with "noAccessToProcedureBodies=true" to have driver generate parameters that represent INOUT strings irregardless of actual parameter types. 总结跟着这个错误在网上找了一下，原来是该用户没有调用存储过程的权限，所以只要赋予proc的权限即可，亲测成功。在MySql中执行如下命令，授予权限。(user@host 是连接数据库的用户名，修改成连接数据库的用户名就行) grant select on mysql.proc to user@host; flush privileges;]]></content>
      <categories>
        <category>Mybatis</category>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Hexo+Git+Nodejs搭建个人博客]]></title>
    <url>%2F2016%2F09%2F11%2FHexo_blog%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;处于好奇，看到别人搞自己的博客，自己也想尝试一番，没想到，弄着弄着就喜欢上了，有时候真是挡也挡不住。遇到的问题也是甚多。刚才发现md的语法原来没有两个空格的，网上有说法使用&amp;emsp;&amp;emsp;反正我是这么用了，因为我用不了输入法的全角的两个空格，我的输入法是win10自带的输入法，所以如果某f有输入法可以尝试一下哦。好了，废话不说了。上教程。 Git 首先也是必须要注册一个Git，注册流程就不多说了，反正都是一样了，然后就新增一个Repository，名字必须是XXX.github.io,也必须是master主干，xxx是你的git的用户名 创建完成后，需要git客户端，客户端下载就不说了，百度都有。 NodeJs&emsp;&emsp;首先要安装nodejs挺多版本的 我的npm是1.4.28版本 作用是生成一些静态的html，安装成功后 可输入命令mpn -v查看当前版本 如果查看不了 证明安装失败，那就要重新安装了。 Hexo 正式安装Hexo 建立文件夹hexo，切换到当前文件夹下，输入命令npm install -g hexo安装hexo，速度的快慢要看你的网速了。 执行初始化hexo,命令：hexo init 启动本地服务命令：hexo server（hexo s也可以） 浏览器输入http://localhost:4000 浏览器有出现hexo的主题页面，证明安装成功了，若没出现，可以看下哪里配置出问题，一般是没有问题的。 配置Github 找到hexo的配置文件_config.yml,这个文件在hexo的根目录下，打开配置文件。进行如下配置： 123type: git repository: git@github.com:wenthywang/wenthywang.github.io.git branch: master 执行命令：npm install hexo-deployer-git --save网上会有很多说法，有的type是github, 还有repository最后面的后缀也不一样，是github.com.git，我也踩了很多坑，我现在的版本是hexo: 3.2.2，执行命令hexo -vsersion就出来了,貌似3.0后全部改成我上面这种格式了。 执行配置命令：hexo deploy(hexo d) 浏览器中输入http://wenthywang.github.io/就行了，我的github的账户叫wenthywang,把这个改成你github的账户名就行了 部署步骤三步走： hexo clean hexo generate(hexo g) hexo deploy(hexo d) 常用命令 hexo new”postName” #新建文章 hexo new page”pageName” #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server） hexo deploy #将.deploy目录部署到GitHub hexo help # 查看帮助 hexo version #查看Hexo的版本]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目中POI导出出现HTML特殊符号的实体--已解决]]></title>
    <url>%2F2016%2F07%2F28%2FPOI_error%2F</url>
    <content type="text"><![CDATA[问题：导出excel 时出现 类似这样的&amp;gt;符号，大概是存到数据库也是这样，然后jsp解析可以解析出来，但是java不认得，需要个人写出解析方法。 废话不说,贴码：123456789101112131415161718 /***转换html特殊符号。* @param content 需要转换的html特殊符号* @param defaultName 默认返回值* @return 转化后实际的符号*/public static String transferHtml(String content, String defaultName) &#123;if(content==null) return defaultName; String html = content;html = StringUtils.replace(html, "&amp;quot;", "\"");html = StringUtils.replace(html, "&amp;lt;", "&lt;");html = StringUtils.replace(html, "&amp;gt;", "&gt;");html = StringUtils.replace(html, "&amp;gt;", "&gt;");html = StringUtils.replace(html, "&amp;sim;", "~");html = StringUtils.replace(html, "&amp;and;", "^");html = StringUtils.replace(html, "&amp;hellip;", "...");return html;&#125; 总结StringUtils用的是apach的工具类。 另外，我也找过度娘，对比了一下StringUtils的replace和String自带的replaceAll方法。 具体就参考 String自带replaceAll和StringUtils工具类replace区别 这博主分析得挺不错的。 另外我也度了一下html特殊符号的对照表，具体参考 HTML 特殊符号编码对照表 总结：根据个人需要把某些常用的特殊符号解析添加到自己的项目中去。]]></content>
      <categories>
        <category>Java</category>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>POI</tag>
        <tag>特殊符号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC静态资源加载出错--未解决]]></title>
    <url>%2F2016%2F02%2F19%2FSpringMVC_error%2F</url>
    <content type="text"><![CDATA[问题：使用mvc：resource配置 web.xml配置是rest风格的/ 服务器启动没问题 访问地址是报404 另外用了default-servlet的方法加载，服务器启动没错，jsp页面加载静态资源要使用绝对路径才能加载，使用相对路径都加载不了。 希望有大神来解答一下]]></content>
      <categories>
        <category>Java</category>
        <category>SpringMVC</category>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringMVC</tag>
        <tag>静态资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC报错]]></title>
    <url>%2F2016%2F01%2F11%2FSpringMVC_erro1%2F</url>
    <content type="text"><![CDATA[spring 报错贴码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.util.ArrayList&lt;?&gt; to type java.util.List&lt;org.springframework.core.io.Resource&gt; for value '[/img/]'; nested exception is org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type java.lang.String to type org.springframework.core.io.Resourceat org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:41)at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:169)at org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:161)at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:450)at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:496)at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:490)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1437)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1396)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1132)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:522)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:607)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:647)at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:598)at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:661)at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:517)at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:458)at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:138)at javax.servlet.GenericServlet.init(GenericServlet.java:158)at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:1284)at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1197)at org.apache.catalina.core.StandardWrapper.allocate(StandardWrapper.java:864)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:134)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:505)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:957)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:423)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1079)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:620)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type java.lang.String to type org.springframework.core.io.Resourceat org.springframework.core.convert.support.GenericConversionService.handleConverterNotFound(GenericConversionService.java:276)at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:172)at org.springframework.core.convert.support.CollectionToCollectionConverter.convert(CollectionToCollectionConverter.java:74)at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:35)... 42 more 总结我在springmvc.xml配置了mvc：resoure，配置信息如下： &lt;mvc:resources location="/js/" mapping="/js/**"/&gt; &lt;mvc:resources location="/img/" mapping="/img/**"/&gt; 如上错误 ，用的是spring3.2的包，程序运行没问题，静态资源可以加载，但是不知道怎么会报这个错，求问怎么解决？？？ 网上找不到解决的办法。求好心人能帮忙解答]]></content>
      <categories>
        <category>Java</category>
        <category>SpringMVC</category>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringMVC</tag>
        <tag>静态资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015最后一日公瑾]]></title>
    <url>%2F2015%2F12%2F31%2F2015_last%2F</url>
    <content type="text"><![CDATA[今天是2015年的最后一天，想想自己14号进来，两个星期好想都在闲逛，带我的@刘俊杰 好像都没有任务给我，然后就不知道干什么就一天了，他叫我继续看api的东西，我基本上全都看完了，大概有个了解，做个demo的也是可以的。他好像不怎么急，我也不想催他，免得他觉得我太过仓促，觉得我对事情不负责这样的。我就继续深究api的东西，昨天看了很久，也明白了很多东西。 公司的api接口是整个系统的所有api调用的接口，公司业务也是很复杂的。PS：怎么博客园插入图片不行的呀，不会插，请博客园的大神教教。 用debug来调试对应的junit的测试方法，然后发现有些地方不知道怎么走。首先是httpclient的模拟客户端发送请求，是发送到哪里的呢，之前没有用过，所以就百度了一下，是发送到对应的url，而发送的地址是a,过了一会是b.原来进行业务操作的时候，是要用户登录验证的，首先要调到验证的url然后返回对应的json数据，通过对应的Token来验证用户是否登录成功，现在我还不清楚token是用来干嘛的，之前在看慕课的微信开发的时候看到过，我也没有实践，不是很清楚了。这个验证应该是网页版的和微信公众号是调用同一个接口，然后就到了restController。 核心代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/*** REST调用入口。* @param request* HttpServletRequest* @param method* String* @return RestResponse* @throws Exception* 异常*/@SuppressWarnings("unchecked")public Object rest(HttpServletRequest request, String method) throws Exception &#123;// 获取接口API名称String api = "";Matcher matcher = uriPattern.matcher(request.getRequestURI());if (matcher.find()) &#123;api = matcher.group(1);&#125;if (StringUtils.isBlank(api)) &#123;return ResponseUtils.getFailed(RestErrorCode.SERVICEISNOTEXIST, "该服务不存在", "");&#125;String channel = request.getHeader("channel");// 请求头信息Map&lt;String, Object&gt; header = new HashMap&lt;String, Object&gt;();header.put("method", method);header.put("channel", channel);if (log.isInfoEnabled()) &#123;log.info("访问接口API:" + api);&#125;// 判断是否合法渠道if (!ChannelConstant.validateChannel(channel)) &#123;return ResponseUtils.getFailed(RestErrorCode.CHANNELNOTEXIST, channel + "填写的渠道不存在，请确认渠道信息", "");&#125;SdkClient.setChannel(channel);Object result = APIFactory.call(getUrl(appVo.getUrl()), header, paramMap);resultMap.put(appVo.getUrl() + appVo.getSort(), result);&#125;Object result = APIFactory.call(getUrl(appVo2.getUrl()), header, paramMap);resultMap.put(appVo2.getUrl() + appVo2.getSort(), result);&#125; catch (FtspException ex) &#123;log.error(appVo2.getUrl() + "自定义错误信息", ex);resultMap.put(appVo2.getUrl() + appVo2.getSort(),FtspJSONUtil.objectToJsonString(ResponseUtils.getFailed(StringUtils.isEmpty(ex.getErrorCode())?RestErrorCode.FTSPEXCEPTION:ex.getErrorCode(), ex.getMessage(), "")));&#125; catch (Exception e) &#123;log.error(appVo2.getUrl() + "请求接口失败", e);resultMap.put(appVo2.getUrl() + appVo2.getSort(),FtspJSONUtil.objectToJsonString(ResponseUtils.getFailed(RestErrorCode.SYSTEMERROR, "服务器繁忙！", "")));&#125;&#125;&#125;&#125;return ResponseUtils.getSuccess("业务操作成功", RestOperateCode.GET_DATA, resultMap);&#125;//小接口return execution(request, api, channel, header);&#125; RESTREST即表述性状态传递（英文：Representational State Transfer，简称REST）是Roy Fielding博士在2000年他的博士论文中提出来的一种软件架构风格。它是一种针对网络应用的设计和开发方式，可以降低开发的复杂性，提高系统的可伸缩性。 目前在三种主流的Web服务实现方案中，因为REST模式的Web服务与复杂的SOAP和XML-RPC对比来讲明显的更加简洁，越来越多的web服务开始采用REST风格设计和实现。例如，Amazon.com提供接近REST风格的Web服务进行图书查找；雅虎提供的Web服务也是REST风格的。 理解 一开始不知道rest是什么，然后就百度了一下，就有了这串东西，然后就有了大概。用户的请求都会经过这个restController，然后就有了一个问题，为什么会到这个Controller不到其他了呢，应该有个xml来配置，还没有找。公司里的xml很多，内容也是够多的，每次看xml的时候很多时候就会蒙掉，因为都用了狠多业务的拼音还有一些不知道什么的东西，这些东西要自己摸索，我也没问是俊杰。至今我也是了解了不少了。 用户进行业务操作会有两个请求这个是必须的。然后里面涉及到的细节问题，我也百度查了下，代码如下：1234private static Pattern uriPattern = Pattern.compile("/api/([\\w\\/]+)"); Matcher matcher = uriPattern.matcher(request.getRequestURI());//使用了正则表达式获得相关字符串 apis.put("sap/fpxx/cgfp", (API) ContextInit.getContext().getBean("ftsp_api_sap_cgfpAPI")); @Component(value = "ftsp_api_sap_djxx_jsfsAPI")// spring的装配功能，对应的组件申明value，来作为beanID List&lt;NameValuePair&gt; nvps = new ArrayList&lt;NameValuePair&gt;();//声明键值 来用来传参数 使用httppost的时候 MD5以前也看过一些加解密技术，也只是有个了解而已，没有深入的了解，深入的研究。 引用：MD5将任意长度的“字节串”映射为一个128bit的大整数，并且是通过该128bit反推原始字符串是困难的，换句话说就是，即使你看到源 程序和算法描述，也无法将一个MD5的值变换回原始的字符串，从数学原 理上说，是因为原始的字符串有无穷多个，这有点象不存在反函数的数学函数。所以，要遇到了md5密码的问题，比较好的办法是：你可以用这个系统中的md5()函数重新设一个密码，如admin，把生成的一串密码的Hash值覆盖原来的Hash值就行了。 MD5是消息摘要算法，数字签名，易懂来说就是每个人的指纹了。一旦对一样东西使用了MD5，就是你按了指纹，没有你的指纹没人能动你的东西。现实生活中，可以模拟人的指纹去干一些不好的事，类似的MD5也不会例外，就好像一开始指纹作为安全的保障，然后现在指纹也变得不安全了，因此MD5也是在劫难逃的。我在想，除了跑字典，还有更好的方式来破解MD5吗？暂时还没有想到，想到我就不是一般人，哈哈。 总结感觉个人学计算机的东西很多，然后很多都有去涉猎了一下，大概有个了解，而并没有对一样自己喜欢东西去研究，去发展，现在做的ｊａｖａ也不是我很想要的，觉得自己就是被生活逼迫到要学一样东西去找工作，而不是因为自己喜欢来学。我比较喜欢安全这方面的东西，安全涉及的东西真的很多，以前想学一些黑客的东西，然后就没了，后面到了游戏外挂，然后也没了然后了，总结了一点，计算机网络一定要学好。哈哈，想着自己计算机网络也是刚好６０分。]]></content>
      <categories>
        <category>Java</category>
        <category>实习</category>
        <category>REST</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Rest</tag>
        <tag>API</tag>
        <tag>MD5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[公瑾科技给我的...]]></title>
    <url>%2F2015%2F12%2F23%2Fkungeek%2F</url>
    <content type="text"><![CDATA[今天主要是浏览了公司的api的各种测试类，在测试的时候出现很多问题，如登陆的非法问题，原因是有个tokenRefresh的类需要更新，然后才能测试api的各种类。测试类的时候，会用debug来运行junit测试，来看看整个测试时怎么走，在走的过程中，也遇到过很多问题，公司里面很多类都通过jar包来管理，所以debug到一定的类时会有找不到类的情况，所以单步的时候很多时候都会头晕了。另外，再看看公司的代码规范文档，有很多问题在代码上面需要注意的。还有一点就是公司的项目用到的技术真的很多，有持续集成的，有ivy的，文档都有说到。公司用到的服务器也是Jenkins，下面内容来自 Jenkins. 持续集成概述什么是持续集成随着软件开发复杂度的不断提高，团队开发成员间如何更好地协同工作以确保软件开发的质量已经慢慢成为开发过程中不可回避的问题。尤其是近些年来，敏捷（Agile） 在软件工程领域越来越红火，如何能再不断变化的需求中快速适应和保证软件的质量也显得尤其的重要。 持续集成正是针对这一类问题的一种软件开发实践。它倡导团队开发成员必须经常集成他们的工作，甚至每天都可能发生多次集成。而每次的集成都是通过自动化的构建来验证，包括自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件。 持续集成的核心价值在于：123持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复过程以节省时间、费用和工作量。持续集成保障了每个时间点上团队成员提交的代码是能成功集成的。换言之，任何时间点都能第一时间发现软件的集成问题，使任意时间发布可部署的软件成为了可能。持续集成还能利于软件本身的发展趋势，这点在需求不明确或是频繁性变更的情景中尤其重要，持续集成的质量能帮助团队进行有效决策，同时建立团队对开发产品的信心。 持续集成的原则业界普遍认同的持续集成的原则包括：1234需要版本控制软件保障团队成员提交的代码不会导致集成失败，常用的版本控制软件有 IBM Rational ClearCase、CVS、Subversion 等。开发人员必须及时向版本控制库中提交代码，也必须经常性地从版本控制库中更新代码到本地。需要有专门的集成服务器来执行集成构建，根据项目的具体实际，集成构建可以被软件的修改来直接触发，也可以定时启动，如每半个小时构建一次。必须保证构建的成功;如果构建失败，修复构建过程中的错误是优先级最高的工作。一旦修复，需要手动启动一次构建。 持续集成系统的组成由此可见，一个完整的构建系统必须包括：123一个自动构建过程，包括自动编译、分发、部署和测试等。一个代码存储库，即需要版本控制软件来保障代码的可维护性，同时作为构建过程的素材库。一个持续集成服务器，Jenkins就是一个配置简单和使用方便的持续集成服务器。 总结上面的介绍估计了解得差不多了。 另外还会有ivy，下面内容是它的简介。 Apache Ivy 是Apache Ant 的一个子项目，提供了一致、可重复、易于维护的方法，来管理项目的所有构建依赖项。它提供了一些强大的功能包括依赖传递，ant集成, maven存储库兼容，持续集成，html报告等。 公司的项目ivy主要是用来依赖管理啊相关的jar包，跟maven差不多，也是管理jar包一种方式，当时我用 ivy的时候，真的很方便，只要在ivy.xml文件配置jar包。相关的jar包会自动加入到项目中来，这个是我学过很好的管理jar包的工具了。 傍晚公司有培训，关于网页爬虫的，用java实现的，看到公司这样的氛围是不错的，以前没有接触过网页爬虫，现在听了一课，觉得在一定程度上会给我们带来便利，于是我很认真了听完了整个培训，了解到爬虫的流程，以及代码的实现，相关的算法，突然觉得有时间还是要看看爬虫有关的东西，会给自己带来更好的知识。 说真的，在这公司给自己带来的收获还是蛮多的，自己也真的学习到很多东西。 今天开了博客，为了让自己在以后的日子能到自己过去是如何成长的。]]></content>
      <categories>
        <category>Java</category>
        <category>实习</category>
      </categories>
      <tags>
        <tag>API</tag>
        <tag>持续集成</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F404.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于我]]></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[王文辉 一个对技术充满好奇的小伙子 涉世未深，有着洞察世界的眼 涉猎了很多程序相关的书籍，喜欢一个人做研究与思考 but…..我更想和别人分享和交流想法…..特别是你…..come on 目前Status 在一家初创公司 做Java开发 每一次完成公司的需求都会有很大的成就感 感觉在学习 不是在工作 Working is Study Working is Study Study is working 过去学习过C++,C#,汇编语言，外挂制作，反编译等。曾经对技术的热爱，你无法想象 。 未来better than present]]></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[分类]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
